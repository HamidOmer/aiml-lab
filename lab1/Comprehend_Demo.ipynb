{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehend Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Copyright [2017]-[2017] Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at\n",
    "\n",
    "http://aws.amazon.com/apache2.0/\n",
    "\n",
    "or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "***\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "#### Identity and Acces Management\n",
    "\n",
    "The user or role that executes the commands must have permissions in AWS Identity and Access Management (IAM) to perform those actions. AWS provides a set of managed policies that help you get started quickly. For our example, you should apply the following managed policy to your user or role:\n",
    "\n",
    "    ComprehendReadOnly\n",
    "\n",
    "Be aware that we recommend you follow AWS IAM best practices for production implementations, which is out of scope for this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Russian Troll Tweets\n",
    "\n",
    "https://github.com/fivethirtyeight/russian-troll-tweets/\n",
    "see: https://fivethirtyeight.com/features/why-were-sharing-3-million-russian-troll-tweets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nv https://raw.githubusercontent.com/fivethirtyeight/russian-troll-tweets/master/IRAhandle_tweets_1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import itertools\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "comprehend = boto3.client('comprehend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest file\n",
    "df = pd.read_csv('IRAhandle_tweets_1.csv')[['language','author','region','following','followers','content']]\n",
    "print(df.size)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a distribution of followers\n",
    "df[['following', 'followers']].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment \n",
    "\n",
    "Use comprehend to extract sentiment.  Comprehend supports a number of languages, but we will be focusing on English\n",
    "\n",
    "see: https://docs.aws.amazon.com/comprehend/latest/dg/how-languages.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of 25 results\n",
    "max_results = 25\n",
    "contents = list(df[df['language'] == 'English']['content'].head(max_results).values)\n",
    "contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentiment back\n",
    "resp = comprehend.batch_detect_sentiment(TextList=contents, LanguageCode='en')\n",
    "sentiments = pd.DataFrame([r['SentimentScore'] for r in resp['ResultList']])\n",
    "sentiments.plot() # TODO: Change colors for results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities\n",
    "\n",
    "Get Entities extracted from this content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some entities back\n",
    "resp = comprehend.batch_detect_entities(TextList=list(contents), LanguageCode='en')\n",
    "entities = list(itertools.chain.from_iterable([r['Entities'] for r in resp['ResultList']]))\n",
    "df_entities = pd.DataFrame(entities)\n",
    "df_entities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top most common person references\n",
    "df_entities[df_entities['Type'] == 'PERSON']['Text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some of the key phrases that are being discussed in these tweets\n",
    "resp = comprehend.batch_detect_key_phrases(TextList=list(contents), LanguageCode='en')\n",
    "df_phrases = pd.DataFrame([[p['Text'] for p in r['KeyPhrases']] for r in resp['ResultList']])\n",
    "df_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
